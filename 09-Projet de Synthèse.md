----
# **Projet Capstone en Data Engineering**
----

ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡
----
*Partie1* 

----

# **AperÃ§u et objectifs**

Au cours de ce projet Capstone, vous allez crÃ©er une solution utilisant plusieurs services AWS que vous connaissez, sans recevoir des instructions dÃ©taillÃ©es Ã©tape par Ã©tape. Certaines sections de cet exercice sont conÃ§ues pour Ãªtre difficiles. Ce projet vous mettra au dÃ©fi de :

- Lancer et configurer un environnement de dÃ©veloppement intÃ©grÃ© (IDE) AWS Cloud9.
- Transformer des fichiers de donnÃ©es au format CSV en format Apache Parquet et les tÃ©lÃ©charger sur Amazon S3.
- CrÃ©er un crawler AWS Glue pour dÃ©duire la structure des donnÃ©es.
- Utiliser Amazon Athena pour interroger les donnÃ©es.
- CrÃ©er une vue Athena.
- Utiliser Amazon QuickSight pour visualiser les donnÃ©es.

# **DurÃ©e et suivi de votre budget**

Ce projet devrait nÃ©cessiter environ 4 heures pour Ãªtre complÃ©tÃ©. L'environnement est persistant : lorsque le minuteur de la session atteint 0:00, la session se termine, mais toutes les donnÃ©es et ressources crÃ©Ã©es dans le compte AWS sont conservÃ©es. Vous pouvez relancer la session Ã  tout moment avant la fin du temps imparti en choisissant "Start Lab".

# **AccÃ¨s aux services AWS**

L'accÃ¨s aux services et actions AWS peut Ãªtre restreint aux besoins de ce projet. Vous pourriez rencontrer des erreurs si vous tentez d'accÃ©der Ã  d'autres services ou d'exÃ©cuter des actions non dÃ©crites dans ce projet.

# **Le jeu de donnÃ©es**

Le site Sea Around Us propose un ensemble de donnÃ©es avec des informations historiques dÃ©taillÃ©es sur les pÃªcheries mondiales, de 1950 Ã  2018. Les donnÃ©es incluent les captures de poissons par pays, les tonnes pÃªchÃ©es, et la valeur de ces captures en dollars amÃ©ricains de 2010.

# **ScÃ©nario**

Vous devez crÃ©er l'infrastructure pour hÃ©berger ces donnÃ©es afin que les analystes puissent crÃ©er des rapports sur l'impact de la pÃªche en haute mer. Vous testerez cette infrastructure en utilisant trois fichiers de donnÃ©es du site Sea Around Us.

# **AccÃ¨s Ã  la console de gestion AWS**

1. **Lancer l'environnement de lab** :
   - Cliquez sur "Start Lab".
   - Attendez que l'icÃ´ne en haut Ã  gauche devienne verte avant de continuer.

2. **Connexion Ã  la console de gestion AWS** :
   - Cliquez sur le lien AWS en haut Ã  gauche pour ouvrir la console dans un nouvel onglet.

# **TÃ¢che 1 : Configuration de l'environnement de dÃ©veloppement**

1. **Observer les dÃ©tails du rÃ´le IAM CapstoneGlueRole**.
2. **CrÃ©er un environnement AWS Cloud9** :
   - Nommer l'environnement `CapstoneIDE`.
   - CrÃ©er une nouvelle instance EC2 t2.micro dans le VPC Capstone, sous-rÃ©seau public Capstone.
3. **CrÃ©er deux buckets S3** :
   - Dans la rÃ©gion us-east-1.
   - Nommer les buckets `data-source-#####` et `query-results-#####` oÃ¹ ##### est un numÃ©ro alÃ©atoire.

4. **TÃ©lÃ©charger les fichiers source .csv** dans l'IDE Cloud9 en utilisant les commandes `wget`.

5. **Observer les donnÃ©es** du fichier `SAU-GLOBAL-1-v48-0.csv` avec la commande `head -6 SAU-GLOBAL-1-v48-0.csv`.

6. **Convertir le fichier CSV en format Parquet** en utilisant pandas et pyarrow.

7. **TÃ©lÃ©charger le fichier Parquet dans le bucket S3 data-source**.

# **TÃ¢che 2 : Utilisation dâ€™un crawler AWS Glue et requÃªtes avec Athena**

1. **Configurer un crawler AWS Glue** :
   - CrÃ©er une base de donnÃ©es `fishdb` et un crawler `fishcrawler`.
   - Configurer le crawler pour utiliser le rÃ´le IAM `CapstoneGlueRole` et explorer le bucket `data-source`.

2. **ExÃ©cuter des requÃªtes SQL avec Athena** sur les donnÃ©es dÃ©couvertes.

# **TÃ¢che 3 : Transformation et ajout de nouveaux fichiers**

1. **Analyser la structure du fichier SAU-EEZ-242-v48-0.csv**.
2. **Modifier les noms de colonnes** pour les aligner avec les autres fichiers et convertir en format Parquet.
3. **TÃ©lÃ©charger le fichier transformÃ© dans le bucket S3**.
4. **Mettre Ã  jour la table dans AWS Glue** en rÃ©exÃ©cutant le crawler.

# **TÃ¢che 4 : Visualisation des rÃ©sultats dans QuickSight**

1. **CrÃ©er un compte QuickSight** et configurer l'accÃ¨s Ã  Athena.
2. **CrÃ©er un jeu de donnÃ©es QuickSight** basÃ© sur la vue `MackerelsCatch`.
3. **CrÃ©er un graphique dans QuickSight** reprÃ©sentant les tonnes de maquereaux pÃªchÃ©es par annÃ©e et par pays.

# **Diagramme ASCII du Pipeline**

```
    +--------------------+
    | Lancer AWS Cloud9  |
    +---------+----------+
              |
              v
    +--------------------+
    | CrÃ©er S3 Buckets   |
    +---------+----------+
              |
              v
    +---------------------------+
    | TÃ©lÃ©charger CSV dans Cloud9|
    +---------+------------------+
              |
              v
    +-----------------------------+
    | Convertir CSV en Parquet    |
    +---------+-------------------+
              |
              v
    +---------------------------+
    | TÃ©lÃ©charger Parquet sur S3 |
    +---------+------------------+
              |
              v
    +------------------------+
    | Configurer Glue Crawler|
    +---------+--------------+
              |
              v
    +-----------------------+
    | RequÃªtes avec Athena  |
    +---------+-------------+
              |
              v
    +------------------------+
    | Visualiser dans QuickSight |
    +------------------------+
```

ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡
----
*Partie2 - Pipeline dÃ©taillÃ© du projet Capstone en Data Engineering**

----



# **1. Lancer et configurer l'environnement de dÃ©veloppement**

**Objectif :** CrÃ©er un environnement de dÃ©veloppement intÃ©grÃ© (IDE) sur AWS Cloud9 pour travailler sur ce projet.

1. **CrÃ©er un environnement Cloud9 :**
   - **Pourquoi ?** AWS Cloud9 est un IDE basÃ© sur le cloud qui vous permet d'Ã©crire, d'exÃ©cuter et de dÃ©boguer votre code Ã  partir de votre navigateur.
   - **Comment faire ?**
     - Allez sur la console AWS, puis recherchez "Cloud9".
     - Cliquez sur "Create environment".
     - Donnez un nom Ã  votre environnement, par exemple `CapstoneIDE`.
     - SÃ©lectionnez "Create a new EC2 instance" et choisissez une instance `t2.micro`, qui est gratuite dans le cadre de l'offre gratuite d'AWS.
     - Assurez-vous que l'instance est dÃ©ployÃ©e dans le VPC Capstone et dans le sous-rÃ©seau public Capstone.
     - Gardez toutes les autres options par dÃ©faut et cliquez sur "Create environment".

2. **VÃ©rifier les rÃ´les IAM :**
   - **Pourquoi ?** Le rÃ´le IAM `CapstoneGlueRole` permet Ã  diffÃ©rents services AWS de communiquer en toute sÃ©curitÃ© et d'accÃ©der aux ressources nÃ©cessaires.
   - **Comment faire ?**
     - Dans la console AWS, recherchez "IAM".
     - Allez dans "Roles" et recherchez `CapstoneGlueRole`.
     - VÃ©rifiez les permissions associÃ©es Ã  ce rÃ´le pour vous assurer qu'il peut accÃ©der aux ressources AWS nÃ©cessaires.

# **2. CrÃ©er et configurer les buckets S3**

**Objectif :** Stocker les fichiers de donnÃ©es dans Amazon S3, un service de stockage d'objets sÃ©curisÃ© et Ã©volutif.

1. **CrÃ©er deux buckets S3 :**
   - **Pourquoi ?** Les buckets S3 vous permettent de stocker et d'organiser les fichiers de donnÃ©es utilisÃ©s dans ce projet.
   - **Comment faire ?**
     - Dans la console AWS, recherchez "S3".
     - Cliquez sur "Create bucket".
     - Nommez le premier bucket `data-source-#####` (remplacez `#####` par un numÃ©ro alÃ©atoire).
     - Nommez le deuxiÃ¨me bucket `query-results-#####`.
     - SÃ©lectionnez la rÃ©gion `us-east-1` pour les deux buckets.
     - Gardez les paramÃ¨tres par dÃ©faut et cliquez sur "Create bucket".

# **3. TÃ©lÃ©charger les fichiers de donnÃ©es CSV**

**Objectif :** Obtenir les fichiers de donnÃ©es CSV nÃ©cessaires au projet et les examiner.

1. **TÃ©lÃ©charger les fichiers CSV :**
   - **Pourquoi ?** Ces fichiers contiennent des donnÃ©es historiques sur la pÃªche, que vous allez transformer et analyser.
   - **Comment faire ?**
     - Ouvrez le terminal dans votre environnement Cloud9.
     - ExÃ©cutez les commandes suivantes pour tÃ©lÃ©charger les fichiers CSV :

       ```bash
       wget https://aws-tc-largeobjects.s3.us-west-2.amazonaws.com/CUR-TF-200-ACDENG-1-91570/lab-capstone/s3/SAU-GLOBAL-1-v48-0.csv
       wget https://aws-tc-largeobjects.s3.us-west-2.amazonaws.com/CUR-TF-200-ACDENG-1-91570/lab-capstone/s3/SAU-HighSeas-71-v48-0.csv
       wget https://aws-tc-largeobjects.s3.us-west-2.amazonaws.com/CUR-TF-200-ACDENG-1-91570/lab-capstone/s3/SAU-EEZ-242-v48-0.csv
       ```

2. **Examiner les donnÃ©es :**
   - **Pourquoi ?** Comprendre la structure des fichiers CSV est essentiel pour les prochaines Ã©tapes de transformation.
   - **Comment faire ?**
     - Pour afficher les premiÃ¨res lignes d'un fichier, utilisez la commande `head` :

       ```bash
       head -6 SAU-GLOBAL-1-v48-0.csv
       ```

     - Cette commande affiche les en-tÃªtes de colonnes et les premiÃ¨res lignes de donnÃ©es, vous donnant un aperÃ§u de ce que contient le fichier.

# **4. Conversion des fichiers CSV en format Parquet**

**Objectif :** Convertir les fichiers CSV en format Parquet, un format de stockage optimisÃ© pour les gros volumes de donnÃ©es.

1. **Installer les outils nÃ©cessaires :**
   - **Pourquoi ?** Vous aurez besoin de bibliothÃ¨ques Python spÃ©cifiques pour effectuer la conversion.
   - **Comment faire ?**
     - Dans le terminal de Cloud9, installez les bibliothÃ¨ques avec la commande suivante :

       ```bash
       sudo pip3 install pandas pyarrow fastparquet
       ```

2. **Convertir le fichier CSV en Parquet :**
   - **Pourquoi ?** Le format Parquet est plus efficace pour le stockage et la requÃªte de donnÃ©es volumineuses.
   - **Comment faire ?**
     - DÃ©marrez une session Python interactive dans le terminal :

       ```bash
       python
       ```

     - Utilisez le code suivant pour lire le fichier CSV et le convertir en Parquet :

       ```python
       import pandas as pd
       df = pd.read_csv('SAU-GLOBAL-1-v48-0.csv')
       df.to_parquet('SAU-GLOBAL-1-v48-0.parquet')
       exit()
       ```

# **5. TÃ©lÃ©chargement des fichiers Parquet sur S3**

**Objectif :** Stocker les fichiers convertis dans le bucket S3.

1. **TÃ©lÃ©charger les fichiers Parquet sur S3 :**
   - **Pourquoi ?** Les fichiers Parquet doivent Ãªtre disponibles dans S3 pour Ãªtre analysÃ©s avec les autres services AWS.
   - **Comment faire ?**
     - Utilisez la commande AWS CLI suivante dans le terminal Cloud9 pour tÃ©lÃ©charger le fichier Parquet :

       ```bash
       aws s3 cp SAU-GLOBAL-1-v48-0.parquet s3://data-source-#####/
       ```

# **6. Utilisation d'un crawler AWS Glue et requÃªtes avec Athena**

**Objectif :** Configurer un crawler AWS Glue pour explorer les donnÃ©es et utiliser Amazon Athena pour interroger les donnÃ©es.

1. **Configurer un crawler AWS Glue :**
   - **Pourquoi ?** AWS Glue vous permet de cataloguer et prÃ©parer vos donnÃ©es pour l'analyse.
   - **Comment faire ?**
     - CrÃ©ez une base de donnÃ©es `fishdb` et un crawler `fishcrawler` dans AWS Glue.
     - Configurez le crawler pour utiliser le rÃ´le IAM `CapstoneGlueRole` et explorer le bucket `data-source`.

2. **ExÃ©cuter des requÃªtes avec Athena :**
   - **Pourquoi ?** Athena vous permet de faire des requÃªtes SQL directement sur vos donnÃ©es stockÃ©es dans S3.
   - **Comment faire ?**
     - AccÃ©dez Ã  Athena via la console AWS, configurez l'Ã©diteur de requÃªtes pour stocker les rÃ©sultats dans votre bucket `query-results`.
     - ExÃ©cutez une requÃªte pour vÃ©rifier que vos donnÃ©es sont correctement cataloguÃ©es.

# **7. Visualisation des rÃ©sultats avec Amazon QuickSight**

**Objectif :** CrÃ©er des visualisations pour analyser les rÃ©sultats de vos requÃªtes.

1. **CrÃ©er un compte QuickSight :**
   - **Pourquoi ?** QuickSight est un outil de visualisation de donnÃ©es qui vous permet de crÃ©er des rapports interactifs.
   - **Comment faire ?**
     - Allez sur la console QuickSight, inscrivez-vous et configurez l'accÃ¨s Ã  Athena.

2. **CrÃ©er des visualisations :**
   - **Pourquoi ?** Pour transformer les donnÃ©es en graphiques et rapports comprÃ©hensibles.
   - **Comment faire ?**
     - CrÃ©ez un nouveau jeu de donnÃ©es Ã  partir de la vue `MackerelsCatch`.
     - CrÃ©ez un graphique reprÃ©sentant les tonnes de maquereaux pÃªchÃ©es par annÃ©e et par pays.

# **Diagramme du Pipeline**


```
      +-------------------------------------+
      | 1. Lancer AWS Cloud9 IDE            |
      +------------------+------------------+
                         |
                         v
      +-------------------------------------+
      | 2. CrÃ©er S3 Buckets                 |
      +------------------+------------------+
                         |
                         v
      +-------------------------------------+
      | 3. TÃ©lÃ©charger fichiers CSV         |
      +------------------+------------------+
                         |
                         v
      +-------------------------------------+
      | 4. Conversion CSV -> Parquet        |
      +------------------+------------------+
                         |
                         v
      +-------------------------------------+
      | 5. TÃ©lÃ©charger Parquet sur S3       |
      +------------------+------------------+
                         |
                         v
      +-------------------------------------+
      | 6. Configurer AWS Glue Crawler      |
      +------------------+------------------+
                         |
                         v
      +-------------------------------------+
      | 7. RequÃªtes SQL avec Athena         |
      +------------------+------------------+
                         |
                         v
      +-------------------------------------+
      | 8. Visualisation avec QuickSight    |
      +-------------------------------------+
```

ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡
----
*Partie3 - Explication des diffÃ©rents composants**

----


| **Service/Outil**        | **RÃ´le**                                                         | **Importance**                                                                                                                                                       |
|--------------------------|------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **AWS Cloud9 IDE**       | Environnement de dÃ©veloppement en ligne.                         | Fournit un IDE complet et accessible depuis le navigateur, Ã©liminant le besoin d'installation locale, avec une intÃ©gration directe avec les services AWS.            |
| **Amazon S3**            | Service de stockage d'objets dans le cloud.                      | Stocke les fichiers de donnÃ©es (CSV, Parquet) de maniÃ¨re sÃ©curisÃ©e et Ã©volutive. Permet un accÃ¨s facile aux donnÃ©es par d'autres services AWS.                       |
| **Fichiers CSV**         | Format de stockage des donnÃ©es tabulaires.                       | Facile Ã  manipuler et Ã  transfÃ©rer entre systÃ¨mes, mais inefficace pour le stockage de grandes quantitÃ©s de donnÃ©es.                                                 |
| **Format Parquet**       | Format de fichier columnar optimisÃ© pour l'analyse de donnÃ©es.   | Offre une meilleure performance de stockage et de requÃªte pour les grands ensembles de donnÃ©es, rÃ©duisant la taille des fichiers et amÃ©liorant la vitesse des requÃªtes. |
| **AWS Glue**             | Service d'intÃ©gration et de prÃ©paration des donnÃ©es.             | Automatise la dÃ©couverte, la transformation, et le catalogage des donnÃ©es, facilitant ainsi l'analyse et l'intÃ©gration des donnÃ©es avec d'autres services AWS.       |
| **AWS Glue Crawler**     | Composant d'AWS Glue pour explorer et cataloguer les donnÃ©es.    | InfÃ¨re automatiquement le schÃ©ma des donnÃ©es et les organise dans un catalogue central, simplifiant l'accÃ¨s aux donnÃ©es pour l'analyse avec Athena.                 |
| **Amazon Athena**        | Service de requÃªtes SQL sans serveur pour analyser les donnÃ©es.  | Permet d'exÃ©cuter des requÃªtes SQL directement sur des donnÃ©es stockÃ©es dans S3 sans besoin de configuration de base de donnÃ©es, offrant une solution rapide et flexible pour l'analyse de donnÃ©es. |
| **Amazon QuickSight**    | Outil de visualisation de donnÃ©es.                               | CrÃ©e des rapports et tableaux de bord interactifs pour interprÃ©ter et partager les rÃ©sultats des analyses de donnÃ©es de maniÃ¨re visuelle et intuitive.              |
| **Amazon IAM**           | Gestion des identitÃ©s et des accÃ¨s.                              | Assure la sÃ©curitÃ© en contrÃ´lant qui peut accÃ©der aux services et ressources AWS, permettant une gestion fine des permissions pour protÃ©ger l'environnement AWS.     |

### **RÃ©sumÃ© de l'Importance**

- **AWS Cloud9 IDE** : Essentiel pour le dÃ©veloppement rapide et l'intÃ©gration directe avec AWS.
- **Amazon S3** : Fondamental pour le stockage sÃ©curisÃ© et centralisÃ© des donnÃ©es.
- **Fichiers CSV** : Utile pour la portabilitÃ© des donnÃ©es, mais limitÃ© en efficacitÃ© pour de grandes quantitÃ©s de donnÃ©es.
- **Format Parquet** : Crucial pour l'optimisation du stockage et de l'analyse des donnÃ©es volumineuses.
- **AWS Glue** : ClÃ© pour la prÃ©paration et le catalogage automatisÃ©s des donnÃ©es.
- **AWS Glue Crawler** : Vital pour dÃ©couvrir et organiser les donnÃ©es automatiquement.
- **Amazon Athena** : Indispensable pour les analyses SQL rapides sans infrastructure supplÃ©mentaire.
- **Amazon QuickSight** : Important pour transformer les donnÃ©es en visualisations comprÃ©hensibles.
- **Amazon IAM** : Crucial pour assurer la sÃ©curitÃ© et la gestion des accÃ¨s dans AWS.



ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡ğŸ¥‡

----
*Partie4 - Explication des diffÃ©rents composants du projet Capstone, QUI FAIT QUOI*

----

### **Partie 3 : Explication des diffÃ©rents composants du projet Capstone**

Dans cette section, nous allons explorer en dÃ©tail les diffÃ©rents composants du pipeline que vous avez mis en place. Nous allons expliquer Ã  quoi sert chaque composant, quand l'utiliser, et ce qu'il fait concrÃ¨tement. Cela vous aidera Ã  mieux comprendre les technologies que vous utilisez et comment elles fonctionnent ensemble pour accomplir les tÃ¢ches requises.

---

### **1. AWS Cloud9 IDE**

**Ã€ quoi Ã§a sert ?**
- AWS Cloud9 est un environnement de dÃ©veloppement intÃ©grÃ© (IDE) en ligne qui vous permet d'Ã©crire, d'exÃ©cuter, et de dÃ©boguer du code directement depuis votre navigateur. 

**Quand l'utiliser ?**
- Vous l'utilisez lorsque vous avez besoin d'un environnement de dÃ©veloppement rapide et facile Ã  configurer, sans avoir Ã  installer des logiciels sur votre ordinateur local. 

**Ã‡a fait quoi ?**
- Cloud9 offre un Ã©diteur de code, un terminal, et des outils de dÃ©bogage dans une seule interface. Il est Ã©galement intÃ©grÃ© avec AWS, ce qui facilite l'accÃ¨s aux services AWS directement depuis l'IDE.

---

### **2. Amazon S3 (Simple Storage Service)**

**Ã€ quoi Ã§a sert ?**
- Amazon S3 est un service de stockage d'objets dans le cloud qui vous permet de stocker et de rÃ©cupÃ©rer n'importe quelle quantitÃ© de donnÃ©es Ã  tout moment, de n'importe oÃ¹.

**Quand l'utiliser ?**
- Vous l'utilisez pour stocker des fichiers tels que des jeux de donnÃ©es, des fichiers Parquet, et d'autres ressources nÃ©cessaires Ã  votre projet. C'est particuliÃ¨rement utile pour stocker des fichiers de grande taille ou pour partager des fichiers entre diffÃ©rents services AWS.

**Ã‡a fait quoi ?**
- S3 vous permet de crÃ©er des "buckets" (des conteneurs de stockage) oÃ¹ vous pouvez uploader, organiser, et gÃ©rer vos fichiers. Il est hautement disponible, sÃ©curisÃ©, et Ã©volutif, ce qui en fait un choix idÃ©al pour le stockage de donnÃ©es dans le cloud.

---

### **3. CSV (Comma-Separated Values) et Parquet**

**Ã€ quoi Ã§a sert ?**
- Les fichiers CSV sont un format de fichier simple utilisÃ© pour stocker des donnÃ©es tabulaires sous forme de texte, oÃ¹ chaque ligne reprÃ©sente un enregistrement et chaque colonne est sÃ©parÃ©e par une virgule. Parquet est un format de fichier optimisÃ© pour le stockage de donnÃ©es volumineuses.

**Quand l'utiliser ?**
- Les fichiers CSV sont utilisÃ©s pour la portabilitÃ© des donnÃ©es entre diffÃ©rents systÃ¨mes et outils, car ils sont largement supportÃ©s. Le format Parquet est utilisÃ© lorsque vous avez besoin d'un stockage plus efficace et performant pour de grandes quantitÃ©s de donnÃ©es.

**Ã‡a fait quoi ?**
- Convertir des fichiers CSV en Parquet permet de rÃ©duire la taille des fichiers et d'amÃ©liorer les performances des requÃªtes sur ces donnÃ©es. Parquet est un format columnar, ce qui signifie qu'il stocke les donnÃ©es par colonne plutÃ´t que par ligne, ce qui est plus efficace pour les requÃªtes analytiques.

---

### **4. AWS Glue**

**Ã€ quoi Ã§a sert ?**
- AWS Glue est un service d'intÃ©gration de donnÃ©es qui facilite la prÃ©paration des donnÃ©es pour l'analyse. Il inclut des fonctionnalitÃ©s pour dÃ©couvrir, transformer, nettoyer, enrichir, et cataloguer les donnÃ©es.

**Quand l'utiliser ?**
- Vous utilisez AWS Glue lorsque vous avez besoin de prÃ©parer et de transformer des donnÃ©es stockÃ©es dans des sources multiples avant de les analyser ou de les visualiser. C'est Ã©galement utile pour automatiser l'exploration et le catalogage des donnÃ©es.

**Ã‡a fait quoi ?**
- AWS Glue utilise des "crawlers" pour explorer vos donnÃ©es, infÃ©rer leur schÃ©ma, et les organiser dans un catalogue central. Cela vous permet de facilement interroger vos donnÃ©es avec d'autres services comme Amazon Athena.

---

### **5. Amazon Athena**

**Ã€ quoi Ã§a sert ?**
- Amazon Athena est un service de requÃªtes SQL sans serveur qui vous permet d'analyser vos donnÃ©es directement dans S3 en utilisant des commandes SQL.

**Quand l'utiliser ?**
- Vous l'utilisez pour exÃ©cuter des requÃªtes SQL sur des donnÃ©es stockÃ©es dans S3 sans avoir besoin de configurer des bases de donnÃ©es ou des clusters de traitement. C'est particuliÃ¨rement utile pour les analyses ad hoc et les requÃªtes rapides sur de grandes quantitÃ©s de donnÃ©es.

**Ã‡a fait quoi ?**
- Athena lit les donnÃ©es depuis S3, les interprÃ¨te en fonction du schÃ©ma dÃ©fini (par exemple via AWS Glue), et exÃ©cute des requÃªtes SQL pour extraire des informations. Vous pouvez ainsi filtrer, agrÃ©ger, et manipuler les donnÃ©es directement depuis votre navigateur.

---

### **6. Amazon QuickSight**

**Ã€ quoi Ã§a sert ?**
- Amazon QuickSight est un service de visualisation de donnÃ©es qui permet de crÃ©er des tableaux de bord interactifs et des rapports visuels Ã  partir de vos donnÃ©es.

**Quand l'utiliser ?**
- Vous l'utilisez pour transformer les rÃ©sultats de vos analyses en visualisations claires et comprÃ©hensibles, que vous pouvez partager avec d'autres membres de votre Ã©quipe ou prÃ©senter aux parties prenantes.

**Ã‡a fait quoi ?**
- QuickSight se connecte Ã  vos sources de donnÃ©es (comme Athena), extrait les donnÃ©es, et vous permet de crÃ©er des graphiques, des cartes, et d'autres visualisations interactives. Il vous aide Ã  tirer des conclusions significatives de vos donnÃ©es de maniÃ¨re visuelle.

---

### **7. Amazon IAM (Identity and Access Management)**

**Ã€ quoi Ã§a sert ?**
- IAM est un service qui vous permet de gÃ©rer de maniÃ¨re sÃ©curisÃ©e l'accÃ¨s aux services et ressources AWS pour vos utilisateurs.

**Quand l'utiliser ?**
- Vous utilisez IAM pour contrÃ´ler qui peut accÃ©der Ã  vos ressources AWS, et pour dÃ©finir les permissions nÃ©cessaires pour chaque utilisateur ou rÃ´le.

**Ã‡a fait quoi ?**
- IAM vous permet de crÃ©er des utilisateurs et des rÃ´les avec des permissions spÃ©cifiques, afin de restreindre l'accÃ¨s Ã  certaines actions ou services AWS. Cela aide Ã  sÃ©curiser votre environnement AWS en s'assurant que chaque utilisateur ou service dispose uniquement des permissions dont il a besoin.

---

### **Pourquoi tout cela est important ?**

Chaque composant de ce pipeline a Ã©tÃ© choisi pour sa capacitÃ© Ã  rendre votre projet plus efficace, sÃ©curisÃ©, et Ã©volutif. En utilisant ces services ensemble, vous crÃ©ez une infrastructure robuste qui peut traiter de grandes quantitÃ©s de donnÃ©es, les analyser, et les visualiser de maniÃ¨re intuitive. C'est cette combinaison de technologies qui permet aux analystes de votre organisation de prendre des dÃ©cisions Ã©clairÃ©es basÃ©es sur des donnÃ©es prÃ©cises et bien prÃ©parÃ©es.



